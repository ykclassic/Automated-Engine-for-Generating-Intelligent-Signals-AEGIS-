name: AEGIS Model Training

on:
  schedule:
    # Retrain weekly on Sundays at 00:00 UTC
    - cron: '0 0 * * 0'
  
  workflow_dispatch:
    inputs:
      optimize_hyperparams:
        description: 'Optimize hyperparameters'
        required: false
        default: 'false'

jobs:
  train-models:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4  # Updated to v4
      
      - name: Set up Python
        uses: actions/setup-python@v5  # Updated to v5
        with:
          python-version: '3.11'
      
      - name: Cache Python dependencies
        uses: actions/cache@v4  # Updated to v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install lightgbm xgboost scikit-learn joblib
      
      - name: Download historical data
        run: |
          python -c "
          from src.core.data_fetcher import DataPipeline
          import yaml
          import os
          
          pipeline = DataPipeline()
          
          with open('config/assets.yaml') as f:
              assets = yaml.safe_load(f)
          
          # Fetch extended history for training
          for tier in ['tier_1']:
              for asset in assets['assets'].get(tier, [])[:3]:  # Top 3 assets
                  symbol = asset['symbol']
                  print(f'Fetching {symbol}...')
                  try:
                      # Force full refresh for training
                      pipeline.fetch_complete_data(symbol, '1h', update_only=False)
                  except Exception as e:
                      print(f'Error: {e}')
          "
      
      - name: Train models
        run: |
          python -c "
          import sys
          sys.path.insert(0, 'src')
          
          from core.data_fetcher import DataPipeline
          from ml.train import TrainingPipeline
          from ml.features import engineer_ml_features
          import pandas as pd
          import yaml
          import json
          import os
          
          # Load data
          pipeline = DataPipeline()
          
          with open('config/assets.yaml') as f:
              assets = yaml.safe_load(f)
          
          all_data = []
          for tier in ['tier_1']:
              for asset in assets['assets'].get(tier, [])[:3]:
                  symbol = asset['symbol']
                  try:
                      df = pipeline.fetch_complete_data(symbol, '1h', update_only=True)
                      if len(df) > 2000:
                          df['symbol'] = symbol
                          all_data.append(df)
                          print(f'Loaded {len(df)} rows for {symbol}')
                  except Exception as e:
                      print(f'Error loading {symbol}: {e}')
          
          if not all_data:
              print('No data available for training')
              exit(1)
          
          # Combine data
          combined = pd.concat(all_data)
          print(f'Total training samples: {len(combined)}')
          
          # Train models
          trainer = TrainingPipeline()
          results = trainer.run_full_training(combined, model_types=['lightgbm', 'xgboost', 'ensemble'])
          
          # Save results
          os.makedirs('data/processed', exist_ok=True)
          with open('data/processed/training_results.json', 'w') as f:
              json.dump(results, f, indent=2, default=str)
          
          print('Training complete!')
          for model, result in results.items():
              if result['status'] == 'success':
                  print(f'{model}: F1={result[\"metrics\"][\"f1_macro\"]:.4f}')
          "
      
      - name: Upload models
        uses: actions/upload-artifact@v4  # Updated to v4
        with:
          name: trained-models
          path: |
            data/models/*.joblib
            data/models/*.json
          retention-days: 90
          overwrite: true
      
      - name: Commit models to data branch
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          git fetch origin data-storage
          git checkout data-storage || git checkout --orphan data-storage
          
          mkdir -p models
          cp data/models/* models/ || true
          
          git add models/
          git commit -m "Update trained models - $(date -u +%Y-%m-%d)" || echo "No changes"
          git push origin data-storage || echo "Nothing to push"
      
      - name: Report results to Discord
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        run: |
          python -c "
          import json
          import os
          import requests
          from datetime import datetime
          
          try:
              with open('data/processed/training_results.json') as f:
                  results = json.load(f)
          except:
              results = {}
          
          webhook = os.environ.get('DISCORD_WEBHOOK')
          if not webhook:
              exit(0)
          
          fields = []
          for model, result in results.items():
              if result.get('status') == 'success':
                  metrics = result.get('metrics', {})
                  value = f\\\"F1: {metrics.get('f1_macro', 0):.3f}, Acc: {metrics.get('accuracy', 0):.3f}\\\"
                  fields.append({'name': model, 'value': value, 'inline': True})
              else:
                  error = result.get('error', 'Unknown error')
                  fields.append({'name': model, 'value': f'Failed: {error}', 'inline': True})
          
          embed = {
              'title': 'ü§ñ Model Training Complete',
              'color': 3447003,
              'fields': fields,
              'timestamp': datetime.utcnow().isoformat()
          }
          
          requests.post(webhook, json={'embeds': [embed]})
          "
      
      - name: Report failure
        if: failure()
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        run: |
          curl -H "Content-Type: application/json" \
            -d "{
              \"embeds\": [{
                \"title\": \"‚ùå Model Training Failed\",
                \"color\": 15158332,
                \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"
              }]
            }" \
            $DISCORD_WEBHOOK || true
